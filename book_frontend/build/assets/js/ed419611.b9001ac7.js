"use strict";(globalThis.webpackChunkbook_frontend=globalThis.webpackChunkbook_frontend||[]).push([[10],{7320(i){i.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/first-phase-hackathon/docs/intro","label":"Physical AI & Humanoid Robotics \ud83e\udd16","docId":"intro","unlisted":false},{"type":"category","label":"ROS 2 Module","items":[{"type":"link","href":"/first-phase-hackathon/docs/ros2-module/ros2-architecture","label":"Chapter 1: ROS 2 Architecture","docId":"ros2-module/ros2-architecture","unlisted":false},{"type":"link","href":"/first-phase-hackathon/docs/ros2-module/python-agents-rclpy","label":"Chapter 2: Python Agents with rclpy","docId":"ros2-module/python-agents-rclpy","unlisted":false},{"type":"link","href":"/first-phase-hackathon/docs/ros2-module/urdf-humanoids","label":"Chapter 3: URDF for Humanoids","docId":"ros2-module/urdf-humanoids","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Digital Twin Module","items":[{"type":"link","href":"/first-phase-hackathon/docs/digital-twin/gazebo-physics-simulation","label":"Chapter 1: Gazebo Physics Simulation","docId":"digital-twin/gazebo-physics-simulation","unlisted":false},{"type":"link","href":"/first-phase-hackathon/docs/digital-twin/unity-interaction","label":"Chapter 2: Unity-Based Interaction","docId":"digital-twin/unity-interaction","unlisted":false},{"type":"link","href":"/first-phase-hackathon/docs/digital-twin/sensor-simulation","label":"Chapter 3: Sensor Simulation","docId":"digital-twin/sensor-simulation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Isaac AI Brain Module","items":[{"type":"link","href":"/first-phase-hackathon/docs/isaac-ai-brain/isaac-sim-synthetic-data","label":"Chapter 1: Isaac Sim & Synthetic Data","docId":"isaac-ai-brain/isaac-sim-synthetic-data","unlisted":false},{"type":"link","href":"/first-phase-hackathon/docs/isaac-ai-brain/isaac-ros-vslam","label":"Chapter 2: Isaac ROS & Visual SLAM","docId":"isaac-ai-brain/isaac-ros-vslam","unlisted":false},{"type":"link","href":"/first-phase-hackathon/docs/isaac-ai-brain/nav2-humanoid-navigation","label":"Chapter 3: Nav2 for Humanoid Navigation","docId":"isaac-ai-brain/nav2-humanoid-navigation","unlisted":false},{"type":"link","href":"/first-phase-hackathon/docs/isaac-ai-brain/perception-to-navigation","label":"Chapter 4: Perception-to-Navigation Flow","docId":"isaac-ai-brain/perception-to-navigation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Vision-Language-Action Module","items":[{"type":"link","href":"/first-phase-hackathon/docs/vla-integration/voice-to-action-pipelines","label":"Chapter 1: Voice-to-Action Pipelines","docId":"vla-integration/voice-to-action-pipelines","unlisted":false},{"type":"link","href":"/first-phase-hackathon/docs/vla-integration/llm-cognitive-planning","label":"Chapter 2: LLM-Based Cognitive Planning","docId":"vla-integration/llm-cognitive-planning","unlisted":false},{"type":"link","href":"/first-phase-hackathon/docs/vla-integration/vla-execution-ros2","label":"Chapter 3: VLA Execution with ROS 2","docId":"vla-integration/vla-execution-ros2","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"chapter-template":{"id":"chapter-template","title":"Chapter Template","description":"This is a template for consistent chapter formatting in the ROS 2 educational book."},"digital-twin/gazebo-physics-simulation":{"id":"digital-twin/gazebo-physics-simulation","title":"Chapter 1: Gazebo Physics Simulation","description":"This chapter provides an introduction to digital twin concepts in robotics and Gazebo physics simulation, covering fundamentals of physics engines, collision detection, and dynamics simulation.","sidebar":"tutorialSidebar"},"digital-twin/sensor-simulation":{"id":"digital-twin/sensor-simulation","title":"Chapter 3: Sensor Simulation","description":"This chapter covers the principles of sensor simulation in digital twin environments, focusing on LiDAR, depth cameras, and IMUs, including noise modeling for realistic sensor data.","sidebar":"tutorialSidebar"},"digital-twin/unity-interaction":{"id":"digital-twin/unity-interaction","title":"Chapter 2: Unity-Based Interaction","description":"This chapter explores Unity as a platform for robotics visualization and interaction, covering 3D visualization principles, user interaction systems, and VR/AR capabilities for immersive simulation.","sidebar":"tutorialSidebar"},"educator-notes":{"id":"educator-notes","title":"Educator Notes for ROS 2 Module","description":"This document provides guidance for educators teaching the ROS 2 module to students with basic Python knowledge."},"intro":{"id":"intro","title":"Physical AI & Humanoid Robotics \ud83e\udd16","description":"Master the Future of Autonomous Systems","sidebar":"tutorialSidebar"},"isaac-ai-brain/isaac-ros-vslam":{"id":"isaac-ai-brain/isaac-ros-vslam","title":"Chapter 2: Isaac ROS & Visual SLAM","description":"This chapter explores NVIDIA Isaac ROS and hardware-accelerated Visual SLAM concepts for robotics perception and mapping.","sidebar":"tutorialSidebar"},"isaac-ai-brain/isaac-sim-synthetic-data":{"id":"isaac-ai-brain/isaac-sim-synthetic-data","title":"Chapter 1: Isaac Sim & Synthetic Data","description":"This chapter provides an introduction to NVIDIA Isaac Sim and synthetic data generation for perception training in AI robotics.","sidebar":"tutorialSidebar"},"isaac-ai-brain/nav2-humanoid-navigation":{"id":"isaac-ai-brain/nav2-humanoid-navigation","title":"Chapter 3: Nav2 for Humanoid Navigation","description":"This chapter covers NVIDIA Isaac Navigation and path planning fundamentals for humanoid robot navigation, including navigation pipelines for bipedal humanoids.","sidebar":"tutorialSidebar"},"isaac-ai-brain/perception-to-navigation":{"id":"isaac-ai-brain/perception-to-navigation","title":"Chapter 4: Perception-to-Navigation Flow","description":"This chapter explains the complete integration between Isaac Sim, Isaac ROS, and Nav2, showing how synthetic data flows through the perception-to-navigation pipeline for humanoid robots.","sidebar":"tutorialSidebar"},"ros2-module/python-agents-rclpy":{"id":"ros2-module/python-agents-rclpy","title":"Chapter 2: Python Agents with rclpy","description":"This chapter focuses on using rclpy, the Python client library for ROS 2, to create agents that can interact with the ROS 2 ecosystem. We\'ll explore how to bridge AI logic to robot controllers using Python.","sidebar":"tutorialSidebar"},"ros2-module/ros2-architecture":{"id":"ros2-module/ros2-architecture","title":"Chapter 1: ROS 2 Architecture","description":"This chapter provides an introduction to ROS 2 architecture, focusing on core concepts for humanoid robot control and AI integration.","sidebar":"tutorialSidebar"},"ros2-module/urdf-humanoids":{"id":"ros2-module/urdf-humanoids","title":"Chapter 3: URDF for Humanoids","description":"This chapter provides an introduction to URDF (Unified Robot Description Format) fundamentals and how to model humanoid robots with joints, links, and sensors. URDF is essential for representing robot models in ROS.","sidebar":"tutorialSidebar"},"vla-integration/llm-cognitive-planning":{"id":"vla-integration/llm-cognitive-planning","title":"Chapter 2: LLM-Based Cognitive Planning","description":"Learning Objectives","sidebar":"tutorialSidebar"},"vla-integration/vla-execution-ros2":{"id":"vla-integration/vla-execution-ros2","title":"Chapter 3: VLA Execution with ROS 2","description":"Learning Objectives","sidebar":"tutorialSidebar"},"vla-integration/voice-to-action-pipelines":{"id":"vla-integration/voice-to-action-pipelines","title":"Chapter 1: Voice-to-Action Pipelines","description":"Learning Objectives","sidebar":"tutorialSidebar"}}}}')}}]);