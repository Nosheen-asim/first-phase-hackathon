"use strict";(globalThis.webpackChunkbook_frontend=globalThis.webpackChunkbook_frontend||[]).push([[766],{5841(e,i,n){n.r(i),n.d(i,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"digital-twin/unity-interaction","title":"Chapter 2: Unity-Based Interaction","description":"This chapter explores Unity as a platform for robotics visualization and interaction, covering 3D visualization principles, user interaction systems, and VR/AR capabilities for immersive simulation.","source":"@site/docs/digital-twin/02-unity-interaction.md","sourceDirName":"digital-twin","slug":"/digital-twin/unity-interaction","permalink":"/first-phase-hackathon/docs/digital-twin/unity-interaction","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/packages/create-docusaurus/templates/shared/docs/digital-twin/02-unity-interaction.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Gazebo Physics Simulation","permalink":"/first-phase-hackathon/docs/digital-twin/gazebo-physics-simulation"},"next":{"title":"Chapter 3: Sensor Simulation","permalink":"/first-phase-hackathon/docs/digital-twin/sensor-simulation"}}');var t=n(4848),s=n(8453);const o={sidebar_position:2},l="Chapter 2: Unity-Based Interaction",a={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Unity Interface for Robotics",id:"introduction-to-unity-interface-for-robotics",level:2},{value:"Key Advantages of Unity for Robotics:",id:"key-advantages-of-unity-for-robotics",level:3},{value:"3D Visualization Principles",id:"3d-visualization-principles",level:2},{value:"Camera Systems",id:"camera-systems",level:3},{value:"Perspective Camera",id:"perspective-camera",level:4},{value:"Orthographic Camera",id:"orthographic-camera",level:4},{value:"Camera Controllers",id:"camera-controllers",level:4},{value:"Lighting and Materials",id:"lighting-and-materials",level:3},{value:"Rendering Pipelines",id:"rendering-pipelines",level:3},{value:"User Interaction Systems for Robot Control",id:"user-interaction-systems-for-robot-control",level:2},{value:"UI Systems",id:"ui-systems",level:3},{value:"Legacy GUI System",id:"legacy-gui-system",level:4},{value:"New UI System (uGUI)",id:"new-ui-system-ugui",level:4},{value:"Unity UI Toolkit",id:"unity-ui-toolkit",level:4},{value:"Input Handling",id:"input-handling",level:3},{value:"Traditional Input",id:"traditional-input",level:4},{value:"VR/AR Input",id:"vrar-input",level:4},{value:"Example Robot Control Interface",id:"example-robot-control-interface",level:3},{value:"VR/AR Capabilities for Immersive Simulation",id:"vrar-capabilities-for-immersive-simulation",level:2},{value:"Virtual Reality (VR)",id:"virtual-reality-vr",level:3},{value:"VR Development Considerations:",id:"vr-development-considerations",level:4},{value:"VR Hardware Support:",id:"vr-hardware-support",level:4},{value:"Augmented Reality (AR)",id:"augmented-reality-ar",level:3},{value:"AR Development Considerations:",id:"ar-development-considerations",level:4},{value:"AR Hardware Support:",id:"ar-hardware-support",level:4},{value:"Example VR Robot Teleoperation:",id:"example-vr-robot-teleoperation",level:3},{value:"Integration with Robotics Frameworks",id:"integration-with-robotics-frameworks",level:2},{value:"ROS Integration",id:"ros-integration",level:3},{value:"Other Robotics Frameworks",id:"other-robotics-frameworks",level:3},{value:"Best Practices for Unity Robotics Interfaces",id:"best-practices-for-unity-robotics-interfaces",level:2},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"User Experience",id:"user-experience",level:3},{value:"Scalability",id:"scalability",level:3},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2}];function d(e){const i={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"chapter-2-unity-based-interaction",children:"Chapter 2: Unity-Based Interaction"})}),"\n",(0,t.jsx)(i.p,{children:"This chapter explores Unity as a platform for robotics visualization and interaction, covering 3D visualization principles, user interaction systems, and VR/AR capabilities for immersive simulation."}),"\n",(0,t.jsx)(i.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(i.p,{children:"After completing this chapter, you will be able to:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Understand Unity interface for robotics visualization"}),"\n",(0,t.jsx)(i.li,{children:"Explain 3D visualization principles"}),"\n",(0,t.jsx)(i.li,{children:"Describe user interaction systems for robot control"}),"\n",(0,t.jsx)(i.li,{children:"Understand VR/AR capabilities for immersive simulation"}),"\n",(0,t.jsx)(i.li,{children:"Implement basic Unity interfaces for robot monitoring and control"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"introduction-to-unity-interface-for-robotics",children:"Introduction to Unity Interface for Robotics"}),"\n",(0,t.jsx)(i.p,{children:"Unity is a powerful cross-platform game engine that has found significant applications in robotics for creating interactive 3D environments and user interfaces. Its real-time rendering capabilities, extensive asset library, and flexible scripting environment make it ideal for developing robotics visualization and interaction systems."}),"\n",(0,t.jsx)(i.p,{children:"Unity can be integrated with the ROS 2 framework from Module 1, allowing for real-time visualization of robot states, sensor data, and environment information. This integration enables operators to monitor and control robots through intuitive 3D interfaces, bridging the gap between complex robotic systems and human operators."}),"\n",(0,t.jsx)(i.h3,{id:"key-advantages-of-unity-for-robotics",children:"Key Advantages of Unity for Robotics:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"High-quality 3D rendering"}),": Realistic visualization of robots and environments"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Cross-platform deployment"}),": Applications run on multiple devices and operating systems"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Extensive asset ecosystem"}),": Large library of 3D models, materials, and tools"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Flexible scripting"}),": C# scripting for custom behaviors and interactions"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"VR/AR support"}),": Native support for virtual and augmented reality applications"]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"3d-visualization-principles",children:"3D Visualization Principles"}),"\n",(0,t.jsx)(i.p,{children:"Effective 3D visualization in robotics requires understanding how to represent complex systems in an intuitive way that helps users understand robot state and environment."}),"\n",(0,t.jsx)(i.h3,{id:"camera-systems",children:"Camera Systems"}),"\n",(0,t.jsx)(i.p,{children:"Unity provides various camera types for different visualization needs:"}),"\n",(0,t.jsx)(i.h4,{id:"perspective-camera",children:"Perspective Camera"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Provides realistic depth perception"}),"\n",(0,t.jsx)(i.li,{children:"Suitable for immersive robot visualization"}),"\n",(0,t.jsx)(i.li,{children:"Mimics human vision with natural perspective"}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"orthographic-camera",children:"Orthographic Camera"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Shows objects without perspective distortion"}),"\n",(0,t.jsx)(i.li,{children:"Useful for precise measurements and top-down views"}),"\n",(0,t.jsx)(i.li,{children:"Maintains consistent object sizes regardless of distance"}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"camera-controllers",children:"Camera Controllers"}),"\n",(0,t.jsx)(i.p,{children:"Unity's camera system can be enhanced with custom controllers for:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Orbiting around the robot"}),"\n",(0,t.jsx)(i.li,{children:"Following the robot in 3D space"}),"\n",(0,t.jsx)(i.li,{children:"Switching between multiple robot views"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"lighting-and-materials",children:"Lighting and Materials"}),"\n",(0,t.jsx)(i.p,{children:"Proper lighting and materials are crucial for realistic visualization:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Directional Lights"}),": Simulate sun or main light source"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Point Lights"}),": Represent localized light sources like robot LEDs"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Materials"}),": Define surface properties like reflectivity and texture"]}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"rendering-pipelines",children:"Rendering Pipelines"}),"\n",(0,t.jsx)(i.p,{children:"Unity offers different rendering pipelines optimized for various use cases:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Built-in Render Pipeline"}),": General purpose, good performance"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Universal Render Pipeline (URP)"}),": Balanced performance and features"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"High Definition Render Pipeline (HDRP)"}),": High-quality rendering for advanced visualization"]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"user-interaction-systems-for-robot-control",children:"User Interaction Systems for Robot Control"}),"\n",(0,t.jsx)(i.p,{children:"Unity's UI and input systems can be leveraged to create intuitive interfaces for robot control and monitoring."}),"\n",(0,t.jsx)(i.h3,{id:"ui-systems",children:"UI Systems"}),"\n",(0,t.jsx)(i.p,{children:"Unity provides several UI systems for robot interaction:"}),"\n",(0,t.jsx)(i.h4,{id:"legacy-gui-system",children:"Legacy GUI System"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Simple immediate mode GUI"}),"\n",(0,t.jsx)(i.li,{children:"Good for debugging and basic interfaces"}),"\n",(0,t.jsx)(i.li,{children:"Less flexible for complex interfaces"}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"new-ui-system-ugui",children:"New UI System (uGUI)"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"More sophisticated and flexible"}),"\n",(0,t.jsx)(i.li,{children:"Supports Canvas-based layouts"}),"\n",(0,t.jsx)(i.li,{children:"Better for complex robot control interfaces"}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"unity-ui-toolkit",children:"Unity UI Toolkit"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Modern UI framework"}),"\n",(0,t.jsx)(i.li,{children:"Uses USS styling similar to CSS"}),"\n",(0,t.jsx)(i.li,{children:"Better for application-style interfaces"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"input-handling",children:"Input Handling"}),"\n",(0,t.jsx)(i.p,{children:"Unity supports various input methods for robot interaction:"}),"\n",(0,t.jsx)(i.h4,{id:"traditional-input",children:"Traditional Input"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Mouse and keyboard controls"}),"\n",(0,t.jsx)(i.li,{children:"Gamepad support"}),"\n",(0,t.jsx)(i.li,{children:"Touch input for mobile devices"}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"vrar-input",children:"VR/AR Input"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Hand tracking and gesture recognition"}),"\n",(0,t.jsx)(i.li,{children:"Controller input for VR devices"}),"\n",(0,t.jsx)(i.li,{children:"Eye tracking where available"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"example-robot-control-interface",children:"Example Robot Control Interface"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.UI;\n\npublic class RobotControllerUI : MonoBehaviour\n{\n    public Slider linearVelocitySlider;\n    public Slider angularVelocitySlider;\n    public Button moveButton;\n    public Text statusText;\n\n    private float linearVelocity = 0f;\n    private float angularVelocity = 0f;\n\n    void Start()\n    {\n        linearVelocitySlider.onValueChanged.AddListener(OnLinearVelocityChanged);\n        angularVelocitySlider.onValueChanged.AddListener(OnAngularVelocityChanged);\n        moveButton.onClick.AddListener(OnMoveButtonClicked);\n    }\n\n    void OnLinearVelocityChanged(float value)\n    {\n        linearVelocity = value;\n        UpdateStatus();\n    }\n\n    void OnAngularVelocityChanged(float value)\n    {\n        angularVelocity = value;\n        UpdateStatus();\n    }\n\n    void OnMoveButtonClicked()\n    {\n        // Send command to robot through ROS or other interface\n        Debug.Log($"Sending command: Linear={linearVelocity}, Angular={angularVelocity}");\n        statusText.text = $"Command sent: {linearVelocity}, {angularVelocity}";\n    }\n\n    void UpdateStatus()\n    {\n        statusText.text = $"Ready to send: {linearVelocity}, {angularVelocity}";\n    }\n}\n'})}),"\n",(0,t.jsx)(i.h2,{id:"vrar-capabilities-for-immersive-simulation",children:"VR/AR Capabilities for Immersive Simulation"}),"\n",(0,t.jsx)(i.p,{children:"Unity's native VR/AR support enables immersive robot simulation and interaction experiences."}),"\n",(0,t.jsx)(i.h3,{id:"virtual-reality-vr",children:"Virtual Reality (VR)"}),"\n",(0,t.jsx)(i.p,{children:"VR in Unity allows users to experience robot environments from a first-person perspective:"}),"\n",(0,t.jsx)(i.h4,{id:"vr-development-considerations",children:"VR Development Considerations:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Performance"}),": Maintain high frame rates (90+ FPS) for comfort"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Comfort"}),": Minimize motion sickness with proper locomotion systems"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Interaction"}),": Design intuitive hand-based interactions"]}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"vr-hardware-support",children:"VR Hardware Support:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Oculus"}),": Rift, Quest series"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"HTC Vive"}),": Index, Pro series"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Valve Index"}),": High-end VR experience"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Windows Mixed Reality"}),": Various headset manufacturers"]}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"augmented-reality-ar",children:"Augmented Reality (AR)"}),"\n",(0,t.jsx)(i.p,{children:"AR overlays digital information onto the real world:"}),"\n",(0,t.jsx)(i.h4,{id:"ar-development-considerations",children:"AR Development Considerations:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Tracking"}),": Accurate real-world object tracking"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Light Estimation"}),": Matching virtual lighting to real environment"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Occlusion"}),": Properly hiding virtual objects behind real ones"]}),"\n"]}),"\n",(0,t.jsx)(i.h4,{id:"ar-hardware-support",children:"AR Hardware Support:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"ARCore"}),": Android devices"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"ARKit"}),": iOS devices"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"HoloLens"}),": Microsoft's mixed reality platform"]}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"example-vr-robot-teleoperation",children:"Example VR Robot Teleoperation:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.XR;\n\npublic class VRTeleoperation : MonoBehaviour\n{\n    public Transform robotBase;\n    public Transform leftController;\n    public Transform rightController;\n\n    void Update()\n    {\n        if (XRSettings.enabled)\n        {\n            // Map controller positions to robot commands\n            Vector3 leftPos = leftController.position;\n            Vector3 rightPos = rightController.position;\n\n            // Calculate differential drive commands\n            float linear = (leftPos.z + rightPos.z) / 2f;\n            float angular = (rightPos.z - leftPos.z) / 2f;\n\n            // Send to robot\n            SendRobotCommand(linear, angular);\n        }\n    }\n\n    void SendRobotCommand(float linear, float angular)\n    {\n        // Implementation to send commands to robot\n        Debug.Log($"VR Command: Linear={linear}, Angular={angular}");\n    }\n}\n'})}),"\n",(0,t.jsx)(i.h2,{id:"integration-with-robotics-frameworks",children:"Integration with Robotics Frameworks"}),"\n",(0,t.jsx)(i.p,{children:"Unity can be integrated with robotics frameworks to create comprehensive simulation and visualization systems."}),"\n",(0,t.jsx)(i.h3,{id:"ros-integration",children:"ROS Integration"}),"\n",(0,t.jsx)(i.p,{children:"Unity can communicate with ROS (Robot Operating System) through:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"ROS#"}),": C# ROS client library"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Unity Robotics Hub"}),": Official Unity package for ROS integration"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Custom TCP/UDP bridges"}),": For specialized communication needs"]}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"other-robotics-frameworks",children:"Other Robotics Frameworks"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Gazebo"}),": Through plugins and bridges"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"V-REP/CoppeliaSim"}),": For simulation integration"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Custom protocols"}),": For proprietary robot systems"]}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"best-practices-for-unity-robotics-interfaces",children:"Best Practices for Unity Robotics Interfaces"}),"\n",(0,t.jsx)(i.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Use object pooling for frequently created/destroyed objects"}),"\n",(0,t.jsx)(i.li,{children:"Implement Level of Detail (LOD) systems for complex models"}),"\n",(0,t.jsx)(i.li,{children:"Optimize materials and textures for real-time performance"}),"\n",(0,t.jsx)(i.li,{children:"Use occlusion culling to avoid rendering hidden objects"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"user-experience",children:"User Experience"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Provide multiple camera views for different perspectives"}),"\n",(0,t.jsx)(i.li,{children:"Use color coding and visual indicators for robot status"}),"\n",(0,t.jsx)(i.li,{children:"Implement intuitive controls that match user expectations"}),"\n",(0,t.jsx)(i.li,{children:"Include visual feedback for robot actions and responses"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"scalability",children:"Scalability"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Design modular interfaces that can accommodate different robot types"}),"\n",(0,t.jsx)(i.li,{children:"Use configuration files to adapt to different robot specifications"}),"\n",(0,t.jsx)(i.li,{children:"Implement scalable UI that works across different display sizes"}),"\n"]}),"\n",(0,t.jsx)(i.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(i.p,{children:"Unity provides a powerful platform for robotics visualization and interaction, offering high-quality 3D rendering, intuitive user interfaces, and immersive VR/AR capabilities. By understanding 3D visualization principles, user interaction systems, and VR/AR capabilities, you can create effective interfaces for robot monitoring, control, and teleoperation."}),"\n",(0,t.jsx)(i.h2,{id:"exercises",children:"Exercises"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Design a Unity interface for monitoring multiple robots simultaneously."}),"\n",(0,t.jsx)(i.li,{children:"Create a simple VR controller for robot teleoperation."}),"\n",(0,t.jsx)(i.li,{children:"Implement a 3D visualization system that shows robot sensor data overlaid on the environment."}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453(e,i,n){n.d(i,{R:()=>o,x:()=>l});var r=n(6540);const t={},s=r.createContext(t);function o(e){const i=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),r.createElement(s.Provider,{value:i},e.children)}}}]);