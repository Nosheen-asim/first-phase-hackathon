"use strict";(globalThis.webpackChunkbook_frontend=globalThis.webpackChunkbook_frontend||[]).push([[557],{28(n,e,i){i.r(e),i.d(e,{assets:()=>r,contentTitle:()=>l,default:()=>g,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"vla-integration/llm-cognitive-planning","title":"Chapter 2: LLM-Based Cognitive Planning","description":"Learning Objectives","source":"@site/docs/vla-integration/02-llm-cognitive-planning.md","sourceDirName":"vla-integration","slug":"/vla-integration/llm-cognitive-planning","permalink":"/first-phase-hackathon/docs/vla-integration/llm-cognitive-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/your-username/your-project-name/tree/main/packages/create-docusaurus/templates/shared/docs/vla-integration/02-llm-cognitive-planning.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Voice-to-Action Pipelines","permalink":"/first-phase-hackathon/docs/vla-integration/voice-to-action-pipelines"},"next":{"title":"Chapter 3: VLA Execution with ROS 2","permalink":"/first-phase-hackathon/docs/vla-integration/vla-execution-ros2"}}');var a=i(4848),o=i(8453);const s={sidebar_position:2},l="Chapter 2: LLM-Based Cognitive Planning",r={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to LLM-Based Cognitive Planning",id:"introduction-to-llm-based-cognitive-planning",level:2},{value:"Planning Components:",id:"planning-components",level:3},{value:"Natural Language Task Translation",id:"natural-language-task-translation",level:2},{value:"Translation Process:",id:"translation-process",level:3},{value:"Example Translation:",id:"example-translation",level:3},{value:"High-Level Reasoning for Robotic Workflows",id:"high-level-reasoning-for-robotic-workflows",level:2},{value:"Reasoning Capabilities:",id:"reasoning-capabilities",level:3},{value:"Integration with Robotics Systems",id:"integration-with-robotics-systems",level:2},{value:"ROS 2 Integration:",id:"ros-2-integration",level:3},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"chapter-2-llm-based-cognitive-planning",children:"Chapter 2: LLM-Based Cognitive Planning"})}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(e.p,{children:"After completing this chapter, you will be able to:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Understand how LLMs enable cognitive planning for robotics"}),"\n",(0,a.jsx)(e.li,{children:"Explain natural language task translation into action plans"}),"\n",(0,a.jsx)(e.li,{children:"Describe high-level reasoning for robotic workflows"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"introduction-to-llm-based-cognitive-planning",children:"Introduction to LLM-Based Cognitive Planning"}),"\n",(0,a.jsx)(e.p,{children:"Large Language Models (LLMs) provide cognitive planning capabilities that bridge natural language commands with robotic action sequences. This extends the AI concepts from Module 3 (Isaac AI Brain) and integrates with the ROS 2 architecture from Module 1."}),"\n",(0,a.jsx)(e.h3,{id:"planning-components",children:"Planning Components:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Task Decomposition"}),": Breaking complex commands into steps"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Context Reasoning"}),": Understanding environmental context"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Action Sequencing"}),": Ordering actions logically"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Constraint Handling"}),": Managing resource and environment constraints"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"natural-language-task-translation",children:"Natural Language Task Translation"}),"\n",(0,a.jsx)(e.p,{children:"LLMs translate natural language tasks into structured action plans for robots."}),"\n",(0,a.jsx)(e.h3,{id:"translation-process",children:"Translation Process:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Command Parsing"}),": Extracting key elements from natural language"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Task Identification"}),": Determining the goal and requirements"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Action Mapping"}),": Connecting concepts to robot capabilities"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Plan Generation"}),": Creating executable sequences"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"example-translation",children:"Example Translation:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:'Input: "Please bring me the blue water bottle from the table"\nOutput: [\n  {"action": "navigate", "target": "table"},\n  {"action": "locate", "object": "blue water bottle"},\n  {"action": "grasp", "object": "blue water bottle"},\n  {"action": "navigate", "target": "user"},\n  {"action": "deliver", "object": "blue water bottle"}\n]\n'})}),"\n",(0,a.jsx)(e.h2,{id:"high-level-reasoning-for-robotic-workflows",children:"High-Level Reasoning for Robotic Workflows"}),"\n",(0,a.jsx)(e.p,{children:"LLMs enable sophisticated reasoning for complex robotic tasks."}),"\n",(0,a.jsx)(e.h3,{id:"reasoning-capabilities",children:"Reasoning Capabilities:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Spatial Reasoning"}),": Understanding object locations and relationships"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Temporal Reasoning"}),": Planning action sequences over time"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Conditional Reasoning"}),": Handling contingencies and exceptions"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Resource Reasoning"}),": Managing available tools and capabilities"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"integration-with-robotics-systems",children:"Integration with Robotics Systems"}),"\n",(0,a.jsx)(e.p,{children:"LLM-based planning integrates with existing robotic frameworks."}),"\n",(0,a.jsx)(e.h3,{id:"ros-2-integration",children:"ROS 2 Integration:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Planning services for task generation"}),"\n",(0,a.jsx)(e.li,{children:"Action clients for execution"}),"\n",(0,a.jsx)(e.li,{children:"State monitoring for plan adjustment"}),"\n",(0,a.jsx)(e.li,{children:"Feedback loops for plan refinement"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(e.p,{children:"LLM-based cognitive planning enables robots to understand and execute complex natural language commands through intelligent task decomposition and reasoning."}),"\n",(0,a.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsx)(e.li,{children:"Describe how an LLM would decompose a multi-step command."}),"\n",(0,a.jsx)(e.li,{children:"Explain the role of context in plan generation."}),"\n"]})]})}function g(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453(n,e,i){i.d(e,{R:()=>s,x:()=>l});var t=i(6540);const a={},o=t.createContext(a);function s(n){const e=t.useContext(o);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:s(n.components),t.createElement(o.Provider,{value:e},n.children)}}}]);